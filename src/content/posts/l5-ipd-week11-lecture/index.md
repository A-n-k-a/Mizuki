---
title: "Innovative Product Development Week11 Lecture"
published: 2025-12-08
pinned: false
description: "Social, Legal, Ethical & Professional Issues"
tags: []
category: "Innovative Product Development"
licenseName: "MIT"
author: "ğŸ¦â€ğŸ”¥ä¸æ­»é¸ŸAnka"
sourceLink: ""
draft: false
date: 2025-12-08
# image:
#   url: ''
#   alt: ''
pubDate: 2025-12-08
---

# Social, Legal, Ethical & Professional Issues
Balancing Power and Responsibility in Technology  
åœ¨æŠ€æœ¯ä¸­å¹³è¡¡æƒåŠ›ä¸è´£ä»»

## Learning Objectives

<table>
    <tr>
        <td><h4>Critical Analysis</h4><h4>æ‰¹åˆ¤æ€§åˆ†æ</h4>Critically analyse the dual impact (risks and benefits) of information and computing technology on society<br>æ‰¹åˆ¤æ€§åœ°åˆ†æä¿¡æ¯æŠ€æœ¯å’Œè®¡ç®—æŠ€æœ¯å¯¹ç¤¾ä¼šäº§ç”Ÿçš„åŒé‡å½±å“ï¼ˆé£é™©å’Œç›Šå¤„ï¼‰</td>
        <td><h4>Legal Understanding</h4><h4>æ³•å¾‹ç†è§£</h4>Understand and identify core legal frameworks related to software development, especially data protection and intellectual property<br>ç†è§£å’Œè¯†åˆ«ä¸è½¯ä»¶å¼€å‘ç›¸å…³çš„æ ¸å¿ƒæ³•å¾‹æ¡†æ¶ï¼Œç‰¹åˆ«æ˜¯æ•°æ®ä¿æŠ¤å’ŒçŸ¥è¯†äº§æƒ</td>
        <td><h4>Ethical Principles</h4><h4>ä¼¦ç†åŸåˆ™</h4>Master core principles of professional ethics and apply codes of conduct to guide decision-making<br>æŒæ¡ä¸“ä¸šä¼¦ç†çš„æ ¸å¿ƒåŸåˆ™ï¼Œå¹¶å°†è¡Œä¸ºå‡†åˆ™åº”ç”¨äºæŒ‡å¯¼å†³ç­–</td>
    </tr>
    <tr>
        <td><h4>Security Standards</h4><h4>å®‰å…¨æ ‡å‡†</h4>Gain preliminary understanding of the seriousness of security-related system development and relevant standards<br>åˆæ­¥äº†è§£ä¸å®‰å…¨ç›¸å…³ç³»ç»Ÿå¼€å‘åŠç›¸å…³æ ‡å‡†çš„ä¸¥é‡æ€§</td>
        <td><h4>PMBOK Connection</h4><h4>PMBOK è”ç³»</h4>Connect these issues with PMBOK's stewardship principles and ethical standards, understanding deeper responsibilities as project professionals<br>å°†è¿™äº›é—®é¢˜ä¸ PMBOK çš„æ²»ç†åŸåˆ™å’Œé“å¾·æ ‡å‡†è”ç³»èµ·æ¥ï¼Œç†è§£ä½œä¸ºé¡¹ç›®ä¸“ä¸šäººå£«çš„æ›´æ·±å±‚æ¬¡è´£ä»»</td>
    </tr>
</table>

---

## In the past 10 weeks, we learned **how** to build.
åœ¨è¿‡å» 10 å‘¨é‡Œï¼Œæˆ‘ä»¬å­¦ä¹ äº†**å¦‚ä½•**æ„å»ºã€‚
## Today, we ask **what** we should build, and **who** is responsible.
ä»Šå¤©ï¼Œæˆ‘ä»¬æ¢è®¨æˆ‘ä»¬åº”è¯¥æ„å»º**ä»€ä¹ˆ**ï¼Œä»¥åŠ**è°**è´Ÿè´£ã€‚

---

## The Power and Responsibility of Technology
This lesson explores the 'boundaries of responsibility' for technology practitioners through four dimensions:  
æœ¬è¯¾é€šè¿‡å››ä¸ªç»´åº¦æ¢è®¨äº†æŠ€æœ¯å®è·µè€…çš„â€œè´£ä»»è¾¹ç•Œâ€ï¼š
- **Social**
- **Legal**
- **Ethical**
- **Professional**

![](wkmd35dFuC2dm0kxReYBn.png)

## Legal Frameworks & Privacy
Data Protection: **GDPR (EU General Data Protection Regulation)**  
æ•°æ®ä¿æŠ¤ï¼š**æ¬§ç›Ÿé€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹ï¼ˆGDPRï¼‰**  
**Core Principles:**  
**æ ¸å¿ƒåŸåˆ™ï¼š**  
1. Legality, Fairness, and Transparency: Clearly inform users why their data is being collected.<br>åˆæ³•æ€§ã€å…¬æ­£æ€§å’Œé€æ˜åº¦ï¼šæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ä¸ºä½•æ”¶é›†å…¶æ•°æ®ã€‚
2. Purpose Limitation: Data used for purpose A cannot be used for purpose B.<br>ç›®çš„é™åˆ¶ï¼šç”¨äºç›®çš„ A çš„æ•°æ®ä¸èƒ½ç”¨äºç›®çš„ Bã€‚
3. Data Minimization: Collect only the data absolutely necessary.<br>æ•°æ®æœ€å°åŒ–ï¼šä»…æ”¶é›†ç»å¯¹å¿…è¦çš„æ•°æ®ã€‚
4. User Rights: Users have the right to access, correct, and delete their data (â€œRight to be forgottenâ€).<br>ç”¨æˆ·æƒåˆ©ï¼šç”¨æˆ·æœ‰æƒè®¿é—®ã€æ›´æ­£å’Œåˆ é™¤ä»–ä»¬çš„æ•°æ®ï¼ˆâ€œè¢«é—å¿˜æƒâ€ï¼‰ã€‚

![](GDPR.png)

## The Red Lines: Legal Frameworks and Compliance
"Legal boundaries define the limits of our innovation. Ignoring them not only risks massive fines but destroys user trust."  
â€œæ³•å¾‹è¾¹ç•Œå®šä¹‰äº†æˆ‘ä»¬çš„åˆ›æ–°æé™ã€‚å¿½è§†å®ƒä»¬ä¸ä»…ä¼šé¢ä¸´å·¨é¢ç½šæ¬¾ï¼Œè¿˜ä¼šç ´åç”¨æˆ·ä¿¡ä»»ã€‚â€  

<table>
    <tr>
        <td><h4>Data Protection</h4><h4>æ•°æ®ä¿æŠ¤</h4><strong>Core Regulation:</strong> GDPR (EU General Data Protection Regulation) as global benchmark<br><strong>æ ¸å¿ƒæ³•è§„ï¼š</strong>GDPRï¼ˆæ¬§ç›Ÿé€šç”¨æ•°æ®ä¿æŠ¤æ¡ä¾‹ï¼‰ä½œä¸ºå…¨çƒåŸºå‡†<br><strong>Key Principles:</strong><br><strong>å…³é”®åŸåˆ™ï¼š</strong><br><span style="color: orange">- Lawful, fair, transparent:</span> Clearly inform users why data is collected<br><span style="color: orange">- åˆæ³•ã€å…¬å¹³ã€é€æ˜ï¼š</span>æ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·ä¸ºä½•æ”¶é›†æ•°æ®<br><span style="color: orange">- Purpose limitation:</span> Data collected for purpose A cannot be used for purpose B<br><span style="color: orange">- ç›®çš„é™å®šï¼š</span>ä¸ºç›®çš„ A æ”¶é›†çš„æ•°æ®ä¸èƒ½ç”¨äºç›®çš„ B<br><span style="color: orange">- Data minimisation:</span> Collect only absolutely necessary data<br><span style="color: orange">- æ•°æ®æœ€å°åŒ–ï¼š</span>ä»…æ”¶é›†ç»å¯¹å¿…è¦çš„æ•°æ®<br><span style="color: orange">- User rights:</span> Access, correct, delete their data ("right to be forgotten")<br><span style="color: orange">- ç”¨æˆ·æƒåˆ©ï¼š</span>è®¿é—®ã€æ›´æ­£ã€åˆ é™¤ä»–ä»¬çš„æ•°æ®ï¼ˆ"è¢«é—å¿˜æƒ"ï¼‰</td>
        <td><h4>Intellectual Property (IP)</h4><h4>çŸ¥è¯†äº§æƒï¼ˆIPï¼‰</h4>- <strong>Copyright:</strong> Protects the "expression form" of code. Emphasizes open source software licenses (MIT, GPL, Apache)<br>- <strong>è‘—ä½œæƒï¼š</strong>ä¿æŠ¤ä»£ç çš„"è¡¨è¾¾å½¢å¼"ã€‚å¼ºè°ƒå¼€æºè½¯ä»¶è®¸å¯ï¼ˆMITã€GPLã€Apacheï¼‰<br>- <strong>Patents:</strong> Protects "technical solutions" or "inventions"<br>- <strong>ä¸“åˆ©ï¼š</strong>ä¿æŠ¤"æŠ€æœ¯è§£å†³æ–¹æ¡ˆ"æˆ–"å‘æ˜"<br>- <strong>Trade Secrets:</strong> Protects company's core algorithms, architecture, etc.<br>- <strong>ä¿å¯†ä¿¡æ¯ï¼š</strong>ä¿æŠ¤å…¬å¸çš„æ ¸å¿ƒç®—æ³•ã€æ¶æ„ç­‰</td>
    </tr>
</table>

<center>"Compliance is not just IT department's responsibility, but every engineer's and product manager's duty."</center>  
<center>"åˆè§„ä¸ä»…ä»…æ˜¯ IT éƒ¨é—¨çš„èŒè´£ï¼Œè€Œæ˜¯æ¯ä¸€ä½å·¥ç¨‹å¸ˆå’Œäº§å“ç»ç†çš„ä¹‰åŠ¡ã€‚"</center>

## Cambridge Analytica and Facebook Data Scandal
### "Your data is shaping the world you see, and even yourself."
**Event Recap:** In 2018, a scandal that shocked the world was exposed. A British political consulting firm named "Cambridge Analytica" was revealed to have illegally obtained personal data from up to 87 million Facebook users without their explicit consent. They accomplished this through a personality test app disguised as academic research, named "thisisyourdigitallife".  
**æ´»åŠ¨å›é¡¾ï¼š** 2018 å¹´ï¼Œä¸€èµ·éœ‡æƒŠä¸–ç•Œçš„ä¸‘é—»è¢«æ­éœ²ã€‚ä¸€å®¶åä¸ºâ€œå‰‘æ¡¥åˆ†æâ€çš„è‹±å›½æ”¿æ²»å’¨è¯¢å…¬å¸è¢«æ›å…‰éæ³•è·å–äº†é«˜è¾¾ 8700 ä¸‡ Facebook ç”¨æˆ·çš„ä¸ªäººä¿¡æ¯ï¼Œè€Œè¿™äº›ç”¨æˆ·å¹¶æœªæ˜ç¡®åŒæ„ã€‚ä»–ä»¬é€šè¿‡ä¸€ä¸ªä¼ªè£…æˆå­¦æœ¯ç ”ç©¶çš„æ€§æ ¼æµ‹è¯•åº”ç”¨â€œthisisyourdigitallifeâ€å®ç°äº†è¿™ä¸€ç›®çš„ã€‚  
This app not only collected data from its respondents but also exploited vulnerabilities in Facebook's platform at the time to scrape data from all of their friends. Cambridge Analytica used this massive dataset to create detailed "psychographic profiles" of users. Based on these profiles, they conducted targeted, highly personalized, and powerfully persuasive (even misleading) political advertising campaigns during political events such as the 2016 US presidential election, attempting to influence voting behavior.  
æ­¤åº”ç”¨ä¸ä»…æ”¶é›†äº†å…¶å—è®¿è€…çš„æ•°æ®ï¼Œè¿˜åˆ©ç”¨äº†å½“æ—¶ Facebook å¹³å°ä¸Šçš„æ¼æ´ï¼Œä»ä»–ä»¬çš„æ‰€æœ‰æœ‹å‹é‚£é‡ŒæŠ“å–æ•°æ®ã€‚å‰‘æ¡¥åˆ†æå…¬å¸åˆ©ç”¨è¿™ä¸ªåºå¤§çš„æ•°æ®é›†åˆ›å»ºäº†ç”¨æˆ·çš„è¯¦ç»†â€œå¿ƒç†ç”»åƒâ€ã€‚åŸºäºè¿™äº›ç”»åƒï¼Œä»–ä»¬åœ¨ 2016 å¹´ç¾å›½æ€»ç»Ÿé€‰ä¸¾ç­‰æ”¿æ²»äº‹ä»¶æœŸé—´è¿›è¡Œäº†æœ‰é’ˆå¯¹æ€§çš„ã€é«˜åº¦ä¸ªæ€§åŒ–çš„ã€æå…·è¯´æœåŠ›ï¼ˆç”šè‡³è¯¯å¯¼æ€§ï¼‰çš„æ”¿æ²»å¹¿å‘Šæ´»åŠ¨ï¼Œè¯•å›¾å½±å“æŠ•ç¥¨è¡Œä¸ºã€‚  

![](MarkZuckerberg.png)

## Often, Something may be legal, but it may not be ethical.
Suppose a software company develops a social networking application. Under local law, the company only needs to state in small print in its user agreement that it will collect user data.  
å‡è®¾ä¸€å®¶è½¯ä»¶å…¬å¸å¼€å‘äº†ä¸€æ¬¾ç¤¾äº¤ç½‘ç»œåº”ç”¨ã€‚æ ¹æ®å½“åœ°æ³•å¾‹ï¼Œè¯¥å…¬å¸åªéœ€åœ¨å…¶ç”¨æˆ·åè®®çš„ç»†å°å­—ä½“ä¸­å£°æ˜å°†æ”¶é›†ç”¨æˆ·æ•°æ®ã€‚  
This is legal. However, if the company knowingly allows this data to be used to unethically manipulate user emotions or to create "user profiles" and sell them to third parties at high prices, without clearly and transparently informing users, then ethical issues arise.  
è¿™æ˜¯åˆæ³•çš„ã€‚ç„¶è€Œï¼Œå¦‚æœå…¬å¸æ˜çŸ¥æ•…çŠ¯ï¼Œå…è®¸ä½¿ç”¨è¿™äº›æ•°æ®ä¸é“å¾·åœ°æ“çºµç”¨æˆ·æƒ…ç»ªæˆ–åˆ›å»ºâ€œç”¨æˆ·æ¡£æ¡ˆâ€å¹¶å°†å…¶é«˜ä»·å–ç»™ç¬¬ä¸‰æ–¹ï¼Œè€Œä¸å‘ç”¨æˆ·æ˜ç¡®é€æ˜åœ°å‘ŠçŸ¥ï¼Œé‚£ä¹ˆå°±ä¼šå¼•å‘é“å¾·é—®é¢˜ã€‚  

![](terms_and_condition.png)

## Social Impact & Fairness
- **The Double-Edged Sword**: Efficiency vs. Inequality.
- **åŒåˆƒå‰‘ï¼š** æ•ˆç‡ä¸ä¸å¹³ç­‰ã€‚
- **Case Study**: Amazon's AI Recruitment Tool (Gender Bias).
- **æ¡ˆä¾‹ç ”ç©¶ï¼š** äºšé©¬é€Šçš„äººå·¥æ™ºèƒ½æ‹›è˜å·¥å…·ï¼ˆæ€§åˆ«åè§ï¼‰ã€‚
- **Key Quote**: "Algorithms are opinions embedded in code."
- **å…³é”®å¼•è¨€ï¼š** â€œç®—æ³•æ˜¯åµŒå…¥ä»£ç ä¸­çš„è§‚ç‚¹ã€‚â€

## The Double-Edged Sword: ICT's Impact on Society
<table>
    <tr>
        <td><h4>The Promise</h4><h4>æ‰¿è¯º</h4>- <strong>Connection & Empowerment:</strong> Global communication, knowledge sharing (Wikipedia), inclusive finance<br>- <strong>è¿æ¥ä¸èµ‹æƒï¼š</strong>å…¨çƒé€šä¿¡ã€çŸ¥è¯†å…±äº«ï¼ˆç»´åŸºç™¾ç§‘ï¼‰ã€åŒ…å®¹æ€§é‡‘è<br>- <strong>Efficiency & Innovation:</strong> Automated production, supply chain optimization, scientific research advancement<br>- <strong>æ•ˆç‡ä¸åˆ›æ–°ï¼š</strong>è‡ªåŠ¨åŒ–ç”Ÿäº§ã€ä¾›åº”é“¾ä¼˜åŒ–ã€ç§‘å­¦ç ”ç©¶è¿›æ­¥<br>- <strong>Convenience:</strong> E-commerce, online education, telemedicine<br>- <strong>ä¾¿åˆ©ï¼š</strong>ç”µå­å•†åŠ¡ã€åœ¨çº¿æ•™è‚²ã€è¿œç¨‹åŒ»ç–—</td>
        <td><h4>The Peril</h4><h4>å±é™©</h4><span style="color: orange"><strong>- Privacy Erosion:</strong></span> Surveillance capitalism, massive data breaches<br><span style="color: orange"><strong>- éšç§ä¾µèš€ï¼š</strong></span>ç›‘æ§èµ„æœ¬ä¸»ä¹‰ã€å¤§è§„æ¨¡æ•°æ®æ³„éœ²<br><span style="color: orange"><strong>- Algorithmic Bias:</strong></span> Reinforcing social prejudices in recruitment, credit, judicial systems<br><span style="color: orange"><strong>ç®—æ³•åè§ï¼š</strong></span>åœ¨æ‹›è˜ã€ä¿¡è´·ã€å¸æ³•ç³»ç»Ÿä¸­å¼ºåŒ–ç¤¾ä¼šåè§<br><span style="color: orange"><strong>- Information Bubbles:</strong></span> Personalized algorithms potentially intensifying social division<br><span style="color: orange"><strong>- ä¿¡æ¯æ³¡æ²«ï¼š</strong></span>ä¸ªæ€§åŒ–ç®—æ³•å¯èƒ½åŠ å‰§ç¤¾ä¼šåˆ†è£‚<br><span style="color: orange"><strong>- Labour Market Disruption:</strong></span> Automation and AI's substitution effect on employment<br><span style="color: orange"><strong>- åŠ³åŠ¨å¸‚åœºé¢ è¦†ï¼š</strong></span>è‡ªåŠ¨åŒ–å’Œäººå·¥æ™ºèƒ½å¯¹å°±ä¸šçš„æ›¿ä»£æ•ˆåº”<br><span style="color: orange"><strong>- Digital Divide:</strong></span> Exacerbating information and opportunity inequality<br><span style="color: orange"><strong>- æ•°å­—é¸¿æ²Ÿï¼š</strong></span>åŠ å‰§ä¿¡æ¯å’Œæœºä¼šçš„ä¸å¹³ç­‰</td>
    </tr>
</table>

## AI Bias
### "Algorithms don't have bias, but the people and data that create them do."
**Event Recap:** The issue of AI bias has emerged in multiple fields. Let's examine two typical examples:  
**æ´»åŠ¨å›é¡¾ï¼š** AI åè§çš„é—®é¢˜åœ¨å¤šä¸ªé¢†åŸŸå‡ºç°ã€‚è®©æˆ‘ä»¬è€ƒå¯Ÿä¸¤ä¸ªå…¸å‹ä¾‹å­ï¼š  
**Amazon's Recruiting AI:** Amazon developed an AI tool to screen resumes in order to improve hiring efficiency. However, they discovered that the system exhibited clear discrimination against female candidates. The reason was that the AI was trained on resume data from the past decade, which came from a tech industry historically dominated by men. As a result, the AI learned to "penalize" candidates whose resumes included terms associated with women (such as "women's chess club captain") and favored resumes that used masculine-coded language. Amazon ultimately abandoned the project.  
**äºšé©¬é€Šçš„æ‹›è˜ AIï¼š** äºšé©¬é€Šå¼€å‘äº†ä¸€ä¸ª AI å·¥å…·æ¥ç­›é€‰ç®€å†ï¼Œä»¥æé«˜æ‹›è˜æ•ˆç‡ã€‚ç„¶è€Œï¼Œä»–ä»¬å‘ç°è¯¥ç³»ç»Ÿå¯¹å¥³æ€§å€™é€‰äººå­˜åœ¨æ˜æ˜¾çš„æ­§è§†ã€‚åŸå› æ˜¯ AI æ˜¯åœ¨è¿‡å»åå¹´ç®€å†æ•°æ®ä¸Šè®­ç»ƒçš„ï¼Œè¿™äº›æ•°æ®æ¥è‡ªå†å²ä¸Šç”±ç”·æ€§ä¸»å¯¼çš„æŠ€æœ¯è¡Œä¸šã€‚å› æ­¤ï¼ŒAI å­¦ä¼šäº†â€œæƒ©ç½šâ€ç®€å†ä¸­åŒ…å«ä¸å¥³æ€§ç›¸å…³çš„æœ¯è¯­ï¼ˆå¦‚â€œå¥³å­è±¡æ£‹ä¿±ä¹éƒ¨é˜Ÿé•¿â€ï¼‰çš„å€™é€‰äººï¼Œå¹¶åçˆ±ä½¿ç”¨ç”·æ€§åŒ–è¯­è¨€çš„ç®€å†ã€‚äºšé©¬é€Šæœ€ç»ˆæ”¾å¼ƒäº†è¿™ä¸ªé¡¹ç›®ã€‚  
**COMPAS Algorithm in the US Judicial System:** COMPAS is an AI tool used to predict a defendant's risk of reoffending, with scores influencing judges' decisions on bail and sentencing. However, an in-depth investigation revealed that the algorithm had significant racial bias: it was twice as likely to incorrectly label Black defendants as "high-risk" compared to white defendants, while white defendants were more likely to be erroneously labeled as "low-risk."  
**ç¾å›½å¸æ³•ç³»ç»Ÿä¸­çš„ COMPAS ç®—æ³•ï¼š** COMPAS æ˜¯ä¸€ç§ AI å·¥å…·ï¼Œç”¨äºé¢„æµ‹è¢«å‘Šå†çŠ¯çš„é£é™©ï¼Œå…¶è¯„åˆ†ä¼šå½±å“æ³•å®˜å¯¹ä¿é‡Šå’Œåˆ¤å†³çš„å†³å®šã€‚ç„¶è€Œï¼Œä¸€é¡¹æ·±å…¥è°ƒæŸ¥æ­ç¤ºäº†è¯¥ç®—æ³•å­˜åœ¨æ˜¾è‘—çš„ç§æ—åè§ï¼šå®ƒå°†é»‘äººè¢«å‘Šé”™è¯¯æ ‡è®°ä¸ºâ€œé«˜é£é™©â€çš„å¯èƒ½æ€§æ˜¯ç™½äººè¢«å‘Šçš„ä¸¤å€ï¼Œè€Œç™½äººè¢«å‘Šæ›´æœ‰å¯èƒ½è¢«é”™è¯¯åœ°æ ‡è®°ä¸ºâ€œä½é£é™©â€ã€‚  

![](I_am_the_code.png)

## The Myth of Neutrality
"Algorithms are opinions embedded in code."  
â€œç®—æ³•æ˜¯åµŒå…¥ä»£ç ä¸­çš„è§‚ç‚¹ã€‚â€  
**Critical Thinking**:  
**æ‰¹åˆ¤æ€§æ€ç»´ï¼š**  
- Bias In -> Bias Out
- åè§è¾“å…¥ -> åè§è¾“å‡º
- Data reflects historical injustice.
- æ•°æ®åæ˜ å†å²ä¸å…¬ã€‚

## Tesla Autopilot Fatal Accidents
"What role should the human behind the wheel play when the machine makes a mistake?"  
äººåœ¨é©¾é©¶æ—¶ï¼Œå½“æœºå™¨å‡ºé”™æ—¶ï¼Œåº”è¯¥æ‰®æ¼”ä»€ä¹ˆè§’è‰²ï¼Ÿ  
**Event Recap:** Tesla's Autopilot is an advanced driver assistance system (ADAS), but not full self-driving. Over the years, there have been several fatal accidents involving Autopilot.  
**äº‹ä»¶å›é¡¾ï¼š** ç‰¹æ–¯æ‹‰çš„è‡ªåŠ¨é©¾é©¶ä»ªæ˜¯ä¸€ç§é«˜çº§é©¾é©¶è¾…åŠ©ç³»ç»Ÿï¼ˆADASï¼‰ï¼Œä½†å¹¶éå®Œå…¨è‡ªåŠ¨é©¾é©¶ã€‚å¤šå¹´æ¥ï¼Œå·²ç»å‘ç”Ÿäº†å‡ èµ·æ¶‰åŠè‡ªåŠ¨é©¾é©¶ä»ªçš„è‡´å‘½äº‹æ•…ã€‚  
The most notorious of these occurred in 2016 when a driver using Autopilot was caught off guard when the vehicle failed to recognize a white semi-trailer truck crossing the road (due to the bright sky in the background), causing the vehicle to run directly under the truck, killing the driver instantly. The investigation found that the driver had placed excessive trust in the system before the accident and had not kept his hands on the steering wheel for an extended period.  
å…¶ä¸­æœ€è‡­åæ˜­è‘—çš„æ˜¯ 2016 å¹´å‘ç”Ÿçš„ä¸€èµ·äº‹æ•…ï¼Œä¸€åä½¿ç”¨è‡ªåŠ¨é©¾é©¶ä»ªçš„é©¾é©¶å‘˜åœ¨è½¦è¾†æœªèƒ½è¯†åˆ«æ­£åœ¨è¿‡é©¬è·¯çš„ç™½è‰²åŠæŒ‚å¡è½¦ï¼ˆç”±äºèƒŒæ™¯ä¸­æ˜äº®çš„å¤©æ°”ï¼‰æ—¶è¢«å“äº†ä¸€è·³ï¼Œå¯¼è‡´è½¦è¾†ç›´æ¥æ’åˆ°å¡è½¦ä¸‹ï¼Œé©¾é©¶å‘˜å½“åœºæ­»äº¡ã€‚è°ƒæŸ¥å‘ç°ï¼Œåœ¨äº‹æ•…å‘ç”Ÿå‰ï¼Œé©¾é©¶å‘˜è¿‡åº¦ä¿¡ä»»äº†è¯¥ç³»ç»Ÿï¼Œå¹¶ä¸”é•¿æ—¶é—´æ²¡æœ‰æ¡ä½æ–¹å‘ç›˜ã€‚  

![](Tesla_Autopilot_Fatal_Accidents.png)

---

![](acm.png)
## Professional Ethics (ACM/IEEE)
**Rule #1**: Public Interest > Employer Interest  
**è§„åˆ™ \#1ï¼š** å…¬å…±åˆ©ç›Š > é›‡ä¸»åˆ©ç›Š  
**Professional Judgment**:  
**ä¸“ä¸šåˆ¤æ–­ï¼š**  
- "Saying **NO** to unsafe features is a skill."
- "**æ‹’ç»**ä¸å®‰å…¨åŠŸèƒ½æ˜¯ä¸€é¡¹æŠ€èƒ½ã€‚"

## PMBOK Connection: Professional Stewardship
<span style="color: orange">"Responsible planning and management of resources entrusted to us"<br>"å¯¹æˆ‘ä»¬æ‰˜ä»˜çš„èµ„æºè¿›è¡Œè´Ÿè´£ä»»çš„è§„åˆ’å’Œç®¡ç†å·¥ä½œ"</span>  
- **Diligence:** Ensuring product safety, reliability, professional standards
- **å‹¤å¥‹ï¼š** ç¡®ä¿äº§å“å®‰å…¨ã€å¯é æ€§ã€ä¸“ä¸šæ ‡å‡†
- **Compliance:** Ensuring project activities follow laws and regulations
- **åˆè§„ï¼š** ç¡®ä¿é¡¹ç›®æ´»åŠ¨éµå¾ªæ³•å¾‹æ³•è§„
- **Trust:** Protecting user data, respecting privacy
- **ä¿¡ä»»ï¼š** ä¿æŠ¤ç”¨æˆ·æ•°æ®ï¼Œå°Šé‡éšç§
- **Care:** Considering long-term impact on society, environment, stakeholders
- **å…³å¿ƒï¼š** è€ƒè™‘åˆ°å¯¹ç¤¾ä¼šã€ç¯å¢ƒã€åˆ©ç›Šç›¸å…³è€…çš„é•¿æœŸå½±å“
#### PMI Code of Ethics and Professional Conduct
PMI's four core valuesâ€”<span style="color: orange"><strong>Responsibility, Respect, Fairness, Honesty</strong></span>â€”provide ultimate behavioral guidance for all issues discussed.
PMI çš„å››ä¸ªæ ¸å¿ƒä»·å€¼è§‚â€”â€”<span style="color: orange"><strong>è´£ä»»ã€å°Šé‡ã€å…¬å¹³ã€è¯šå®</strong></span>â€”â€”ä¸ºæ‰€æœ‰è®¨è®ºçš„é—®é¢˜æä¾›æœ€ç»ˆçš„è¡Œä¸ºæŒ‡å¯¼ã€‚

---
## You are not just coders.
ä½ ä»¬ä¸ä»…ä»…æ˜¯ç¨‹åºå‘˜ã€‚
## You are the **stewards** of the digital future.
ä½ æ˜¯æ•°å­—æœªæ¥çš„**å®ˆæŠ¤è€…**ã€‚
## **Build Responsibly.**
**è´Ÿè´£ä»»åœ°æ„å»ºã€‚**
